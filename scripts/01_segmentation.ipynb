{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a46cd3",
   "metadata": {},
   "source": [
    "#### load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309f3883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd \n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from autodistill_grounded_sam import GroundedSAM\n",
    "from autodistill.detection import CaptionOntology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0e175b",
   "metadata": {},
   "source": [
    "#### configuration\n",
    "\n",
    "- set your working directory to the root of the repo\n",
    "- append the scripts folder to the python path, so you can load the utility script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffedb032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r\"D:\\git-repos\\mluerig\\grounded-sam-intro\")\n",
    "sys.path.append(\"scripts\")\n",
    "from utils import model_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b09ccb",
   "metadata": {},
   "source": [
    "#### load the model\n",
    "\n",
    "- initialize GroundedSAM model with your search ontology, in this case, for butterfly detection\n",
    "- set text and box thresholds for detection sensitivity (0.1 = everything above 10% detection confidence will be included)\n",
    "- I'd recommend setting those sensitivies not too high, and instead, filter our unwanted masks yourself later \n",
    "- you can add multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3e1da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to load grounding dino directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4319.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "base_model = GroundedSAM(\n",
    "    ontology=CaptionOntology({\n",
    "        \"butterfly\": \"butterfly\",\n",
    "        # \"label\": \"label\", ## example of adding more classes\n",
    "        # \"ruler\": \"ruler\", ## example of adding more classes\n",
    "        }),\n",
    "    text_threshold = 0.1,\n",
    "    box_threshold = 0.1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc85b1",
   "metadata": {},
   "source": [
    "#### collect all images\n",
    "\n",
    "- this works with nested folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84076a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "## point to image root dir\n",
    "root_dir = fr\"data_raw\\input_imgs\\butterflies\"\n",
    "\n",
    "## loop through all subfolders\n",
    "dict_imgs = defaultdict(list)\n",
    "for root, dirs, files in tqdm(list(os.walk(root_dir))):\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(root, file_name)\n",
    "        parts = os.path.normpath(file_path).split(os.sep)\n",
    "        info = {\n",
    "            \"image_name\": file_name,\n",
    "            \"image_path\": file_path,\n",
    "        }\n",
    "        dict_imgs[file_name].append(info)\n",
    "\n",
    "## make a df        \n",
    "flattened_data = []\n",
    "for key, value_list in dict_imgs.items():\n",
    "    for value in value_list:\n",
    "        flattened_entry = {}\n",
    "        flattened_entry.update(value)\n",
    "        flattened_data.append(flattened_entry)\n",
    "data_imgs = pd.DataFrame(flattened_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43c349",
   "metadata": {},
   "source": [
    "#### set up how the results are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca611d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mask_root_dir = fr\"data_raw/segmentation_masks-butterflies/\"\n",
    "path_seg_data = fr\"data/segmentation_results-butterflies.csv\"\n",
    "os.makedirs(path_mask_root_dir, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(path_seg_data), exist_ok=True)\n",
    "dict_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a346e8",
   "metadata": {},
   "source": [
    "#### run segmentation\n",
    "\n",
    "- depending on the size of your dataset, and whether you use a GPU or not, this can take a while\n",
    "- this replicates the nested folder structure of your input folder, if it exists\n",
    "- use a sensible minimum area cutoff to not include small, likely noisy detections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "793d5602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmenting images:   0%|          | 0/8 [00:00<?, ?it/s]The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "None of the inputs have requires_grad=True. Gradients will be None\n",
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "                                                                \r"
     ]
    }
   ],
   "source": [
    "min_area = 10000 ## min area in px\n",
    "\n",
    "pbar = tqdm(total=len(data_imgs), position=0, leave=False, desc=\"Segmenting images\")\n",
    "for idx1, row in data_imgs.iterrows():\n",
    "    \n",
    "    ## pull info from df\n",
    "    image_name = row[\"image_name\"]\n",
    "    image_path = row[\"image_path\"]     \n",
    "    base_image_name = os.path.splitext(image_name)[0]\n",
    "\n",
    "    ## path management, preserve nested structure\n",
    "    rel_path = os.path.relpath(image_path, root_dir)\n",
    "    rel_dir = os.path.dirname(rel_path) \n",
    "    mask_dir = os.path.join(path_mask_root_dir, rel_dir)\n",
    "    \n",
    "    # load image\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        assert image is not None, \"Failed to load the image.\"\n",
    "    except:\n",
    "        dict_results[base_image_name] = {\"result\": \"no_image\", \"image_name\": image_name}\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "    \n",
    "    ## do prediction\n",
    "    result = base_model.predict(image)\n",
    "    \n",
    "    # Check for masks and process\n",
    "    if len(result.mask) > 0:\n",
    "        for idx2, (area, mask) in enumerate(zip(result.area, result.mask)):\n",
    "            \n",
    "            ## save mask if area > min_area\n",
    "            mask_name = base_image_name + f\"_{idx2+1}.png\"\n",
    "            if area > min_area:\n",
    "                roi, info = model_helpers.filter_mask(image, mask, min_area)\n",
    "                os.makedirs(mask_dir, exist_ok=True)\n",
    "                saved = cv2.imwrite(os.path.join(mask_dir, mask_name), roi)\n",
    "            else:\n",
    "                info = {}\n",
    "                                \n",
    "            # Store info\n",
    "            info[\"confidence\"] = result.confidence[idx2]\n",
    "            info[\"area\"] = area\n",
    "            info[\"mask_idx\"] = idx2 + 1\n",
    "            info[\"image_name\"] = image_name\n",
    "            dict_results[mask_name] = info\n",
    "        pbar.update(1)\n",
    "    else:\n",
    "        # Add an empty entry if no detections\n",
    "        dict_results[mask_name] = {\"result\": \"no_detection\", \"image_name\": image_name}\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17810f5d",
   "metadata": {},
   "source": [
    "#### save results to csv\n",
    "- this saves the results of your dictionary to a table\n",
    "- use it to inspect the detected masks (e.g., confidence, size, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5352da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to dt   \n",
    "data_results = pd.DataFrame.from_dict(dict_results, orient=\"index\").reset_index()\n",
    "data_results = data_results.rename(columns={\"index\":\"mask_name\"})\n",
    "data_results = data_results[data_results['bbox'].notna()]\n",
    "data_results.rename(columns={\"confidence\":\"confidence_seg\"}, inplace=True)\n",
    "data_results[[\"mask_idx\", \"area\", \"diameter\"]] = data_results[[\"mask_idx\", \"area\", \"diameter\"]].apply(lambda x: x.astype('int'))\n",
    "data_results = data_results[['image_name', 'mask_idx','mask_name','confidence_seg','area','bbox', 'center','diameter']]\n",
    "data_results = data_results.sort_values(by=['image_name', \"mask_idx\"])\n",
    "data_results.to_csv(path_seg_data, index=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grounded-sam1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
