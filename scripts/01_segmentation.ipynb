{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309f3883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CUDA not available. GroundingDINO will run very slowly.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd \n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from autodistill_grounded_sam import GroundedSAM\n",
    "from autodistill.detection import CaptionOntology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffedb032",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"D:\\git-repos\\mluerig\\grounded-sam-intro\")\n",
    "sys.path.append(\"scripts\")\n",
    "from utils import model_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = GroundedSAM(\n",
    "    ontology=CaptionOntology({\"mouse\": \"mouse\",}),\n",
    "    text_threshold = 0.1,\n",
    "    box_threshold = 0.1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84076a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## point to image root dir\n",
    "root_dir = fr\"data_raw\\input_imgs\\test_mice_copy\"\n",
    "\n",
    "## loop through all subfolders\n",
    "dict_imgs = defaultdict(list)\n",
    "for root, dirs, files in tqdm(list(os.walk(root_dir))):\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(root, file_name)\n",
    "        parts = os.path.normpath(file_path).split(os.sep)\n",
    "        info = {\n",
    "            \"image_name\": file_name,\n",
    "            \"parent_name\": parts[-2],\n",
    "            \"image_path\": file_path,\n",
    "        }\n",
    "        dict_imgs[file_name].append(info)\n",
    "\n",
    "## make a df        \n",
    "flattened_data = []\n",
    "for key, value_list in dict_imgs.items():\n",
    "    for value in value_list:\n",
    "        flattened_entry = {}\n",
    "        flattened_entry.update(value)\n",
    "        flattened_data.append(flattened_entry)\n",
    "data_imgs = pd.DataFrame(flattened_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca611d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = \"test_mice\"\n",
    "\n",
    "path_mask_root_dir = fr\"data_raw/segmentation_masks-{group}/\"\n",
    "path_seg_dict = fr\"data_raw/results/segmentations-{group}.pkl\"\n",
    "path_seg_data = fr\"data_raw/results/segmentations-{group}.csv\"\n",
    "\n",
    "dict_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_area = 1000 ## min area in px\n",
    "save_intervall = 100 ## save every x images\n",
    "\n",
    "pbar = tqdm(total=len(data_imgs), position=0, leave=False, desc=\"Segmenting images\")\n",
    "for idx1, row in data_imgs.iterrows():\n",
    "\n",
    "    image_name = row[\"image_name\"]\n",
    "    parent_name = row[\"parent_name\"]\n",
    "    image_path = row[\"image_path\"]     \n",
    "\n",
    "    base_image_name = os.path.splitext(image_name)[0]\n",
    "\n",
    "    # Load image and predict\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        assert image is not None, \"Failed to load the image.\"\n",
    "    except:\n",
    "        dict_results[base_image_name] = {\"result\": \"no detections\", \"parent_name\": parent_name, \"image_name\": image_name}\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "    \n",
    "    ## do prediction\n",
    "    result = base_model.predict(image)\n",
    "    \n",
    "    # Check for masks and process\n",
    "    if len(result.mask) > 0:\n",
    "        for idx2, (area, mask) in enumerate(zip(result.area, result.mask)):\n",
    "            mask_name = base_image_name + f\"_{idx2+1}.png\"\n",
    "            if area > min_area:\n",
    "                \n",
    "                # Filter mask and save\n",
    "                # try:\n",
    "                roi, info = model_helpers.filter_mask(image, mask, min_area)\n",
    "                path_mask_dir = os.path.join(path_mask_root_dir, parent_name, mask_name)\n",
    "                os.makedirs(os.path.dirname(path_mask_dir), exist_ok=True)\n",
    "                saved = cv2.imwrite(path_mask_dir, roi)\n",
    "                # except:\n",
    "                #     info = {}\n",
    "            else:\n",
    "                info = {}\n",
    "                                \n",
    "            # Store info\n",
    "            info[\"confidence\"] = result.confidence[idx2]\n",
    "            info[\"area\"] = area\n",
    "            info[\"mask_idx\"] = idx2 + 1\n",
    "            info[\"image_name\"] = image_name\n",
    "            info[\"parent_name\"] = parent_name\n",
    "            dict_results[mask_name] = info\n",
    "        pbar.update(1)\n",
    "    else:\n",
    "        # Add an empty entry if no detections\n",
    "        dict_results[mask_name] = {\"result\": \"no detections\", \"parent_name\": parent_name, \"image_name\": image_name}\n",
    "    pbar.update(1)\n",
    "    \n",
    "    if (idx1 + 1) % save_intervall == 0:\n",
    "        various.save_dict(dict_results, path_dict_results, format=\"pickle\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5352da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## final save\n",
    "various.save_dict(dict_results, path_dict_results, format=\"pickle\")\n",
    "       \n",
    "## to dt   \n",
    "data_results = pd.DataFrame.from_dict(dict_results, orient=\"index\").reset_index()\n",
    "data_results = data_results.rename(columns={\"index\":\"mask_name\"})\n",
    "data_results = data_results[data_results['bbox'].notna()]\n",
    "data_results.rename(columns={\"confidence\":\"confidence_seg\"}, inplace=True)\n",
    "data_results[[\"mask_idx\", \"area\", \"diameter\"]] = data_results[[\"mask_idx\", \"area\", \"diameter\"]].apply(lambda x: x.astype('int'))\n",
    "data_results = data_results[['species','image_name', 'mask_idx','mask_name','confidence_seg','area','bbox', 'center','diameter']]\n",
    "data_results = data_results.sort_values(by=['species', 'image_name', \"mask_idx\"])\n",
    "data_results.to_csv(path_data_results, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cfda10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grounded-sam1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
